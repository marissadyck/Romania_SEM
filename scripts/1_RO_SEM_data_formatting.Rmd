---
title: "Romania SEM Data Formatting"
author: "Marissa Dyck"
date: "2024-08-07"
output:
  pdf_document:
    toc: true
  html_document:
    theme: journal
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Before you begin

## Notes

A few notes about this script.

If you are want to run through the full analysis with the published data make sure you download the whole (Romania_SEM repository)[https://github.com/marissadyck/Romania_SEM] from the author's (Marissa A. Dyck) GitHub. This will ensure you have all the files, data, and proper folder structure you will need to run this code and associated analyses.

Also make sure you open RStudio through the R project (Romania_SEM.Rproj) in the repo this will automatically set your working directory to the correct place (wherever you saved the repository) and ensure you don't have to change the file paths for the data. 

If you have question please email the author,   

Marissa A. Dyck   
Postdoctoral research fellow    
University of Victoria    
School of Environmental Studies     
Email: [marissadyck17@gmail.com](marissadyck17@gmail.com)    


## R and RStudio

Before starting you should ensure you have the latest version of R and RStudio downloaded. This code was generated under R version 4.2.3 and with RStudio version 2024.04.2+764.    

You can download R and RStudio [HERE](https://posit.co/download/rstudio-desktop/)   


## R markdown

This script is written in R markdown and thus uses a mix of coding markup languages and R. If you are planning to run this script with new data or make any modifications you will want to be familiar with some basics of R markdown or transfer code in the code chunks to a script.

Below is an R markdown cheatsheet to help you get started,    
[R markdown cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf)    


## Install packages

If you don't already have the following packages installed, use the code below to install them. *Note this code chunk will NOT automatically run when the file is knit since eval=FALSE is set, because I already have the packages and don't want to reinsall them every time. You will need to run this chunk separately if you need to install these packages*. You only need to do this once.

```{r install packages, eval=FALSE}

install.packages('tidyverse') # data tidying, visualization, and much more; this will load all tidyverse packages, can see complete list using tidyverse_packages()
install.packages('janitor') # used for cleaning up data
```


## Load libraries

Then load the packages to your library. You will need to do this anytime you start a new session in R.

```{r libraries}

library(tidyverse) # data tidying, visualization, and much more; this will load all tidyverse packages, can see complete list using tidyverse_packages()
library(janitor) # used for cleaning up data
```

# Data

## Camera data

We will start with the camera data from our remote camera traps that were deployed in Romania. 

### Import data

We can load both data files at once and rowbind them since they have the same columns using a function in the *Purrr* package.

```{r load camera data}

cameras <- 
  
# provide file path (e.g. folders to find the data)
  file.path('data/raw',
            
            # provide the file names
            c('cams_data_winter_2018-2019.csv',
              'cams_data_autumn_2018-2019.csv')) %>% 
  
   # use purrr map to read in files, the ~.x is a placeholder that refers to the object before the last pipe (aka the list of data we are reading in) so all functions inside the map() after ~.x will be performed on all the objects in the list we provided
  map_dfr(~.x %>%
        read_csv(.))
                 
```


View this data, by using `View(cameras)` or clicking on the object in the *environment*.
 
### Format data

We need to do a bit of data cleaning to make this file usable for our analysis. The code chunk below will,    

1. read in the data again   
2. specify how to read in the columns   
3. set the column names to lowercase for easier coding later   
4. reformat some columns so data is appropriate for analysis   
5. and finally select only to columns of data we need   

```{r format camera data}

cameras <- 
  
# provide file path (e.g. folders to find the data)
  file.path('data/raw',
            
            # provide the file names
            c('cams_data_winter_2018-2019.csv',
              'cams_data_autumn_2018-2019.csv')) %>% 
  
   # use purrr map to read in files, the ~.x is a placeholder that refers to the object before the last pipe (aka the list of data we are reading in) so all functions inside the map() after ~.x will be performed on all the objects in the list we provided
  map_dfr(~.x %>%
        read_csv(.,
                 
                col_types = cols(Session = col_factor(),
                                 TrapCode = col_factor(),
                                     Impact = col_factor(),
                                     .default = col_number()))) %>% 
  
   # set column names to lowercase
  set_names(
    names(.) %>% 
      tolower()) %>% 
  
  # Combine specific CORINE Land Cover types for forest into one
  
  mutate(clc_forest = (clc311 + clc312 + clc313)) %>% 
  
  # select only columns of interest for SEM analysis and merginf with animals data frame
  
  select(session, trapcode, z, denslocalr, tri5, clc_forest, distnatlro, distsettle, diststream, distlocalr) 
                 
```

### Data checks

Let's take a look at this data using a few common functions

```{r explore cameras data}

# check data structure
str(cameras)

# summary stats for columns
summary(cameras)

# print first few rows
head(cameras,
     n = 25)
```
 
Everything looks good. 140 trap sites (trapcode), no NAs



## Animal data
 Now let's import the detection data from the camera traps. 
 
### Import data

This is a csv file with information from the camera traps provided by (Foundation Conservation Carpathia) [https://www.carpathia.org/], their staff and volunteers have already tagged the images and identified the species present in each.

```{r load animals data}

# load species occurrence data
animals <- read_csv('data/raw/animals_on_cameras_2018-2019.csv') 
```

View this data, by using `View(animals)` or clicking on the object in the *environment*.

### Format data

We also need to do a bit of data cleaning to make this file usable for our analysis. The code chunk below will,    

1. read in the data again   
2. specify how to read in the columns   
3. set the column names to lowercase for easier coding later    
4. recode some of the entries   
5. remove data that we won't use    

```{r format animals data}

# load species occurrence data

animals <- read_csv('data/raw/animals_on_cameras_2018-2019.csv',
                      
                      # specify how to read in columns
                      col_types = cols(X = col_number(),
                                       Y = col_number(),
                                       Z = col_number(),
                                       StartDate = col_date(format = '%Y-%m-%d'),
                                       EndDate = col_date(format = '%Y-%m-%d'),
                                       RDate = col_date(format = '%Y-%m-%d'),
                                       Time = col_time(format = '%H:%M:%S'),
                                       NoAnimals = col_integer(),
                                       Sequence = col_integer(),
                                       Comments = col_character(),
                                       .default = col_factor()  #.default sets any unspecified columns to this type
                      )) %>% 
  
  # set column names to lowercase
  set_names(
    names(.) %>% 
      tolower()) %>% 
  
  # select just the columns of data we need to count species observations per season and trap
  select(session, date, trapcode, type, species) %>% 
  
  # recode species data to group some types
  mutate( species = recode(species, 
                           'Vehicle' = 'Human',
                           'Cow' = 'Livestock',
                           'Goat' = 'Livestock',
                           'Horse' = 'Livestock',
                           'Beech marten' = 'Mustelid',
                           'Pine marten' = 'Mustelid',
                           'Least weasel' = 'Mustelid',
                           'European polecat' = 'Mustelid')) %>% 
  
  
  # remove  session 1 (trial period) and unknown species 
  filter(! session == '1',
         ! is.na(species),
         ! species == 'Unknown',
         
         # select just the pictures to avoid duplicate occurrences at the same site
         type == 'P')
```

Will get an error about parsing issues just ignore.

### Data checks


#### Overall

Let's take a look at this data using a few common functions

```{r explore animals data}

# check data structure
str(animals)

# summary stats for columns
summary(animals)

# print first few rows
head(animals,
     n = 25)
```

Let's do a few more specific data checks to make sure everything is correct

#### Species names

Let's make sure the species entries are correct and no spelling mistakes 

```{r check species}

levels(animals$species)
```
 
 Everything looks good here
 
#### Trapcodes

Let's check that no trap codes are mis-entered or repeated etc.

```{r check trapcode}

levels(animals$trapcode)
```
Hmm there seem to be more sites than in the camera data, this may be because it's still counting the trapcodes from session 1 even though we filtered those out in the data formatting steps. Let's try something else to check if the trapcodes match the camera data

```{r check trapcodes}

# check which trapcodes are in animals that are not in the cameras data
setdiff(levels(animals$trapcode),
        levels(cameras$trapcode))

# and vice versa
setdiff(levels(cameras$trapcode),
        levels(animals$trapcode))
```
It looks like the animals data has extra trapcodes but no missing ones from the cameras data. I think it is still retaining the codes from session 1 in Rs memory for some reason after we used the filter function to remove them, let's check by looking for any data from the trapcodes printed above

```{r}
animals %>% 
  
  filter(trapcode == '40')
```

No data, so we are good 

##  Trap effort

Now we need to load in the trap effort so we can check that we can quanitfy camera effort for each site. 

```{r trap effort data}

effort <- file.path('data/raw',
                    
                    # provide file names
                    c('Trap_Effort_S2.csv',
                    'Trap_Effort_S3.csv')) %>% 
  
  map(~.x %>% 
        
        read_csv(.) %>% 
        
        # set column names to lowercase for coding ease
        set_names(
          names(.) %>% 
            tolower())) %>% 
  
  purrr::set_names(c('session_2',
                     'session_3'))

```

### Data checks

```{r effort data check}

str(effort)
```
What I need to do is add a column to each data frame that specifies the session, and add a column that totals the number of active camera days from each occasion since this data were originally formatted for a different occupancy analysis with 2-week camera occasions

### Format data

#### Add columns

The code below adds two new columns to each data frame separately that specifies the session, and totals the number of days the camera was functioning from the raw data. 
```{r format effort}

# add session column to each and total effort column
effort$session_2 <- effort$session_2 %>% 
  
  add_column(.,
             session = 2) %>% 
  
  mutate(trap_effort = rowSums(across(occasion_1:occasion_8)))

head(effort$session_2)


effort$session_3 <- effort$session_3 %>% 
  
  add_column(.,
             session = 3) %>% 
  
   mutate(trap_effort = rowSums(across(occasion_1:occasion_7)))

head(effort$session_3)
```

#### Bind data

Now with both select just the columns we need and the we will rowbind the data so we have one data frame with info for both sessions

```{r}
effort_tidy <- effort %>% 
  
  map(~.x %>% 
        
        select(trapcode,
               session,
               trap_effort) %>% 
        
         # make session a factor to join with other data
  mutate(session = as.factor(session)))
  
 
# check dta
head(effort_tidy)

# bind data
trap_effort <- 
bind_rows(effort_tidy)
```


Remove messy data lists that we don't need 

```{r}
rm(effort)
rm(effort_tidy)
```



### Join animals and effort data and count species occurrences

Now we want to join the animals and effort data frames so we have a single data frame for our analysis, and also we will count the number of species occurrences (independent detections) from the animal data and add a column for this as it will be the response variable in our analysis
```{r join data}
animals_effort <- animals %>% 
  
  # join data frames
  left_join(trap_effort,
            by = c('session', 'trapcode')) %>% 
  
   # group data
  group_by(session, trapcode, species, trap_effort) %>% 
  
  # use summarize to species ocurrences
  summarize(n = n(),
            .groups = 'drop') %>% 
  
  # ensure only one row per unique combination is returned
  distinct(session, trapcode, species, .keep_all = TRUE) %>% 
  
  # pivot the data to wide format so each species has a column
  pivot_wider(names_from = species,
              values_from = n,
              values_fill = list(n = 0))

# check data
head(animals_effort)
```



### Merge camera and occurrence

Finally let's merge the camera and occurrence data so we have all the data (response variables, covariates, summary info) in one data frame

```{r merge cams and occurrences}

# merge species occurrence data with the camera site variables from cams

ro_sem_data_effort <- animals_effort %>% 
  
  # join data
  left_join(cameras,
    by = c('session', 'trapcode')) %>% 
  
  # remove any NAS
  drop_na() %>% 
  
  # set the species column names to lowercase and clean them up
  set_names(
    names(.) %>% 
      tolower()) %>% 
  clean_names() %>% 
  rename(hare = european_hare)
```


### Save new cleaned data

```{r save data}
write_csv(ro_sem_data_effort,
          'data/processed/ro_sem_data_effort_2018-2019.csv')
```



